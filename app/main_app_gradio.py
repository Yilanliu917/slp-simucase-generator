import os
import json
from dotenv import load_dotenv
from typing import List

import gradio as gr
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_anthropic import ChatAnthropic
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough

# --- 1. CONFIGURATION and SETUP ---
load_dotenv()
DB_PATH = "data/slp_knowledge_base/" # Assuming updated path
EMBEDDING_MODEL = "text-embedding-3-small"
MAX_CONDITIONS = 5

# --- Pydantic Models ---
class BackgroundInfo(BaseModel):
    medical_history: str = Field(description="Relevant medical history.")
    parent_concerns: str = Field(description="Summary of concerns from parents.")
    teacher_concerns: str = Field(description="Summary of concerns from teachers.")

class StudentProfile(BaseModel):
    name: str = Field(description="A realistic, anonymized student name.")
    age: int = Field(description="The student's age.")
    grade_level: str = Field(description="The student's grade level.")
    gender: str = Field(description="The student's gender.")
    background: BackgroundInfo = Field(description="Detailed background information.")

class SimuCaseFile(BaseModel):
    student_profile: StudentProfile
    annual_goals: List[str]
    latest_session_notes: List[str]

# --- 2. REFACTORED CORE LOGIC ---
initialized_models = {}

def get_llm(model_choice: str):
    """Initializes or retrieves a cached LLM."""
    if model_choice in initialized_models:
        return initialized_models[model_choice]

    print(f"Initializing model: {model_choice}...")
    
    model_map = {
        "gpt-4o": ChatOpenAI,
        "gemini-1.5-pro": ChatGoogleGenerativeAI,
        "claude-3-opus": ChatAnthropic,
        "claude-3.5-sonnet": ChatAnthropic
    }
    model_name_map = {
        "gpt-4o": "gpt-4o",
        "gemini-1.5-pro": "gemini-1.5-pro-latest",
        "claude-3-opus": "claude-3-opus-20240229",
        "claude-3.5-sonnet": "claude-3-5-sonnet-20240620"
    }
    
    model_class = model_map.get(model_choice)
    model_name = model_name_map.get(model_choice)
    
    if not model_class:
        raise ValueError(f"Invalid model selected: {model_choice}")
        
    llm = model_class(model=model_name, temperature=0.7).with_structured_output(SimuCaseFile)
    initialized_models[model_choice] = llm
    return llm

def process_generation_request(mode, *args, progress=gr.Progress()):
    """Gathers all UI inputs, builds a task list, and generates profiles."""
    
    tasks = []
    if mode == "Single Condition":
        num_students, model, grade, disorders = args[0:4]
        for _ in range(int(num_students)):
            tasks.append({"grade": grade, "disorders": disorders, "model": model})
    else: # Multiple Conditions
        for i in range(MAX_CONDITIONS):
            is_visible = args[i * 4 + 4] 
            if is_visible:
                grade, disorders, num, model = args[i*4 : i*4 + 4]
                for _ in range(int(num)):
                    tasks.append({"grade": grade, "disorders": disorders, "model": model})

    if not tasks:
        raise gr.Error("No generation tasks specified. Please add conditions and student numbers.")

    embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)
    vectorstore = Chroma(persist_directory=DB_PATH, embedding_function=embeddings)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 10})
    
    # --- START: MODIFIED TEMPLATE ---
    # Re-introducing the expert role and detailed instructions for better performance.
    template = """
    You are an expert school-based CCC-SLP creating a simulation case file based on a user's request.
    Use the following retrieved clinical context to generate a comprehensive, ethical, and realistic case file.
    Structure your output to perfectly match the requested schema.

    Context:
    {context}

    Question:
    {question}
    """
    # --- END: MODIFIED TEMPLATE ---
    prompt = ChatPromptTemplate.from_template(template)
    
    all_profiles_md = ""
    progress(0, desc="Starting Generation...")
    for i, task in enumerate(tasks):
        disorder_string = ", ".join(task['disorders'])
        question = f"Generate a case file for a {task['grade']} student with: {disorder_string}."
        
        progress((i + 1) / len(tasks), desc=f"Generating profile {i+1}/{len(tasks)} with {task['model']}...")
        
        llm = get_llm(task['model'])
        rag_chain = {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
        response = rag_chain.invoke(question)
        
        profile = response.student_profile
        profile_md = f"""
        ---
        ### **Profile {i+1}: {profile.name}** (Generated by: {task['model']})
        **Age:** {profile.age} | **Grade:** {profile.grade_level} | **Gender:** {profile.gender}
        #### Background
        - **Medical History:** {profile.background.medical_history}
        - **Parent Concerns:** {profile.background.parent_concerns}
        - **Teacher Concerns:** {profile.background.teacher_concerns}
        #### Annual IEP Goals
        """ + "\n".join([f"- {goal}" for goal in response.annual_goals])
        profile_md += "\n#### Latest 3 Session Notes\n" + "\n".join([f"- **Session {j+1}:** {note}" for j, note in enumerate(response.latest_session_notes)])
        all_profiles_md += profile_md

    return all_profiles_md

# --- 4. CREATE THE GRADIO UI ---
if __name__ == "__main__":
    grade_levels = ["Pre-K", "Kindergarten", "1st Grade", "2nd Grade", "3rd Grade", "4th Grade", "5th Grade", 
                    "6th Grade", "7th Grade", "8th Grade", "9th Grade", "10th Grade", "11th Grade", "12th Grade"]
    disorder_types = ["Speech Sound", "Articulation", "Phonology", "Fluency", 
                      "Expressive Language", "Receptive Language", "Language", "Voice"]
    model_choices = ["gpt-4o", "gemini-1.5-pro", "claude-3-opus", "claude-3.5-sonnet"]

    with gr.Blocks(theme=gr.themes.Soft(), title="SLP SimuCase Generator") as ui:
        gr.Markdown("# Scalable SLP SimuCase Generator")
        
        gen_mode = gr.Radio(["Single Condition", "Multiple Conditions"], label="Select Generation Mode", value="Single Condition")

        with gr.Group(visible=True) as single_condition_group:
            with gr.Row():
                num_students_single = gr.Number(label="Number of Students", value=1, minimum=1, step=1)
                model_single = gr.Dropdown(choices=model_choices, label="AI Model", value="gpt-4o")
            single_grade = gr.Dropdown(choices=grade_levels, label="Grade Level", value="1st Grade")
            single_disorders = gr.Dropdown(choices=disorder_types, label="Disorder(s)", value=["Articulation"], multiselect=True)

        multi_condition_rows = []
        with gr.Group(visible=False) as multi_condition_group:
            visible_rows = gr.State(1)
            for i in range(MAX_CONDITIONS):
                with gr.Row(visible=(i==0)) as row:
                    gr.Markdown(f"**Set {i+1}**")
                    grade = gr.Dropdown(choices=grade_levels, label="Grade", value="1st Grade")
                    disorders = gr.Dropdown(choices=disorder_types, label="Disorder(s)", value=["Articulation"], multiselect=True)
                    num = gr.Number(label="# Students", value=1, minimum=1, step=1)
                    model = gr.Dropdown(choices=model_choices, label="Model", value="gpt-4o")
                    visibility = gr.Checkbox(value=(i==0), visible=False)
                    multi_condition_rows.append([grade, disorders, num, model, visibility])
            with gr.Row():
                add_button = gr.Button("Add Condition Set")
                remove_button = gr.Button("Remove Last Set")
        
        generate_button = gr.Button("Generate Case Files", variant="primary")
        output_display = gr.Markdown(label="Generated Case Files")
        
        def update_visibility(mode):
            return gr.update(visible=(mode == "Single Condition")), gr.update(visible=(mode == "Multiple Conditions"))
        gen_mode.change(fn=update_visibility, inputs=gen_mode, outputs=[single_condition_group, multi_condition_group])
        
        def update_rows(count):
            return [gr.update(visible=i < count) for i in range(MAX_CONDITIONS)]

        def add_row(count):
            return min(count + 1, MAX_CONDITIONS)
        
        def remove_row(count):
            return max(count - 1, 1)

        row_visibility_components = [row[0] for row in multi_condition_rows]
        add_button.click(fn=add_row, inputs=visible_rows, outputs=visible_rows)
        remove_button.click(fn=remove_row, inputs=visible_rows, outputs=visible_rows)
        visible_rows.change(fn=update_rows, inputs=visible_rows, outputs=row_visibility_components)

        all_multi_inputs = [item for sublist in multi_condition_rows for item in sublist]
        generate_button.click(
            fn=process_generation_request,
            inputs=[gen_mode, num_students_single, model_single, single_grade, single_disorders] + all_multi_inputs,
            outputs=output_display
        )
    
    ui.launch()